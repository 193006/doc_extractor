Certainly! Here's a brief overview of TruEra with reference links:

- **AI Quality Platform**: TruEra provides an AI Quality and Observability Platform to analyze and improve AI/ML modeling projects¹.
- **Monitoring & Diagnostics**: It offers monitoring for production models with real-time alerts and diagnostics for model development and root cause analysis¹.
- **Model Lifecycle Support**: TruEra supports the entire model lifecycle, from feature development to training, evaluation, and deployment¹.
- **Framework Compatibility**: The platform is compatible with popular Python modeling frameworks and can work with custom-built models, as well as those built using DataRobot, Dataiku, Sagemaker, or Algorithmia¹.

For more detailed information, you can visit the official documentation and resources provided by TruEra¹⁴.

Source: Conversation with Bing, 5/6/2024
(1) Welcome to TruEra! - User Documentation. https://docs.truera.com/1.41/public/full/.
(2) AI Resources Archive - TruEra. https://truera.com/resources/.
(3) Getting Started - User Documentation - docs.truera.com. https://docs.truera.com/1.44/public/getting-started/.
(4) Getting Started - User Documentation - docs.truera.com. https://docs.truera.com/1.41/public/getting-started/.



1. **Patrons** provides an automated evaluation platform that detects Large Language Model (LLM) mistakes at scale⁶. It offers services like LLM Failure Monitoring & Observability, and Test Suite Generation⁷⁸.
2. **Brain trust Data** offers a stack for building AI products, including LLM applications. It provides tools for scoring model performance, logging, and visualizing outputs¹⁴.
3. **Langsmith** offers an evaluation function that takes in a set of inputs and outputs from your chain, agent, or model, and returns a score (or multiple scores). It allows you to run evaluations on your application via Datasets²⁸.
4. **Galileo** provides tools for GenAI evaluation, experimentation, and observability. It offers features like logging runs, visualizing components, and facilitating collaboration[^10^].
5. **Databricks RAG studio** provides a suite of RAG tools to help users build high-quality, production LLM apps using their enterprise data²⁴.
6. **DeepEval** is an open-source evaluation framework for LLMs. It evaluates LLM outputs based on metrics such as G-Eval, hallucination, answer relevancy, RAGAS, etc¹.
7. **Truelens** is a software tool that helps you to objectively measure the quality and effectiveness of your LLM-based applications using feedback functions¹⁹.

Source: Conversation with Bing, 5/6/2024
(1) Patronus AI | Automated AI Evaluation. https://www.patronus.ai/.
(2) Patronus AI | Suite. https://www.patronus.ai/product/features.
(3) Patronus AI - LLM benchmarking and evaluation tool - PC Guide. https://www.pcguide.com/ai/patronus-ai/.
(4) BrainTrust Data. https://www.braintrustdata.com/.
(5) Evaluation Overview | ️ ️ LangSmith. https://docs.smith.langchain.com/evaluation.
(6) The Generative AI Evaluation Company - Galileo. https://www.rungalileo.io/.
(7) Creating High Quality RAG Applications with Databricks. https://www.databricks.com/blog/building-high-quality-rag-applications-databricks.
(8) GitHub - confident-ai/deepeval: The LLM Evaluation Framework. https://github.com/confident-ai/deepeval.
(9) TruLens for LLMs. https://www.trulens.org/.
(10) Quick Introduction | DeepEval - The Open-Source LLM Evaluation Framework. https://docs.confident-ai.com/docs/getting-started.
(11) Introduction | DeepEval - The Open-Source LLM Evaluation Framework. https://docs.confident-ai.com/docs/confident-ai-introduction.
(12) GitHub - AI-App/DeepEval: The Evaluation Framework for LLMs. https://github.com/AI-App/DeepEval.
(13) DeepEval: Simplifying Evaluation Of Language Learning Models (LLMs .... https://www.ai-summary.com/deepeval-simplifying-evaluation-of-language-learning-models-llms/.
(14) Patronus AI Introduces Groundbreaking LLM Evaluation Tool for Regulated .... https://robots.net/news/patronus-ai-introduces-groundbreaking-llm-evaluation-tool-for-regulated-industries/.
(15) A Metrics-First Approach to LLM Evaluation - Galileo. https://www.rungalileo.io/blog/metrics-first-approach-to-llm-evaluation.
(16) Galileo Evaluate® : Rapid Evaluation of Prompts, Chains and RAG systems .... https://docs.rungalileo.io/galileo/gen-ai-studio-products/galileo-evaluate.
(17) Galileo - Accelerate unstructured data evaluation and experimentation .... https://www.arfi.ai/tool/galileo.
(18) Getting started with Braintrust — Braintrust. https://www.braintrustdata.com/docs.
(19) GitHub - braintrustdata/autoevals: AutoEvals is a tool for quickly and .... https://github.com/braintrustdata/autoevals.
(20) Braintrust Data offers enterprises faster way to evaluate LLMs. https://venturebeat.com/ai/braintrust-data-wants-to-make-enterprise-ai-better-with-faster-evaluations/.
(21) autoevals — Braintrust. https://www.braintrustdata.com/docs/autoevals/python.
(22) truera/trulens: Evaluation and Tracking for LLM Experiments - GitHub. https://github.com/truera/trulens.
(23) Build and Evaluate LLM Apps with LlamaIndex and TruLens - TruEra - Medium. https://truera.com/build-and-evaluate-llm-apps-with-llamaindex-and-trulens/.
(24) Building Better LLM Apps: Evaluating and Tracking LLM Experiments with .... https://www.toolify.ai/ai-news/building-better-llm-apps-evaluating-and-tracking-llm-experiments-with-trulens-2209348.
(25) Best Practices for LLM Evaluation of RAG Applications - Databricks. https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG.
(26) Best Practices for LLM Evaluation of RAG Applications - Databricks. https://www.databricks.com/blog/announcing-mlflow-28-llm-judge-metrics-and-best-practices-llm-evaluation-rag-applications-part.
(27) LLM Chatbot With Retrieval Augmented Generation (RAG) and DBRX. https://notebooks.databricks.com/demos/llm-rag-chatbot/index.html.
(28) Databricks creates suite of RAG tools for LLM app production. https://www.kmworld.com/Articles/ReadArticle.aspx?ArticleID=161803.
(29) LangSmith Evaluation Deep Dive | ️ ️ LangSmith. https://docs.smith.langchain.com/cookbook/introduction.
(30) Evaluate and trace with LangSmith to Master LLM optimization. https://datasciencedojo.com/blog/llm-evaluation-with-langsmith/.
(31) Langsmith for LLM Application Evaluation & Monitoring. https://livingdatalab.com/posts/2023-08-16-langsmith-for-llm-application-evaluation.html.
(32) Using LangSmith to test LLMs and AI applications. https://blog.logrocket.com/langsmith-test-llms-ai-applications/.
(33) undefined. https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm.
(34) undefined. https://docs.smith.langchain.com/evaluation/quickstart.
(35) undefined. https://docs.smith.langchain.com/evaluation/faq/manage-datasets.
(36) undefined. https://www.trulens.org/trulens_eval/getting_started/core_concepts/.
(37) undefined. https://github.com/truera/trulens@BRANCH.

api_key="rterfdgdfgdgdf"

from rouge_score import rouge_scorer

def calculate_rouge_scores(reference, hypothesis):
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)
    scores = scorer.score(' '.join(reference), ' '.join(hypothesis))
    
    rouge1 = scores['rouge1'].fmeasure
    rouge2 = scores['rouge2'].fmeasure
    rougeL = scores['rougeL'].fmeasure
    rougeLsum = scores['rougeLsum'].fmeasure
    
    return rouge1, rouge2, rougeL, rougeLsum

# Example usage:
reference = ["The cat sat on the mat"]
hypothesis = ["The cat sat on the rug"]
rouge1, rouge2, rougeL, rougeLsum = calculate_rouge_scores(reference, hypothesis)
print("ROUGE-1:", rouge1)
print("ROUGE-2:", rouge2)
print("ROUGE-L:", rougeL)
print("ROUGE-Lsum:", rougeLsum)

## 16/04/25 19:50
import re
import pandas as pd

def count_sql_attributes(query):
    # Define the SQL clauses and join types
    clauses = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'JOIN', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']

    # Initialize a dictionary to store the counts and attributes
    counts = {clause: 0 for clause in clauses}
    attributes = {clause: [] for clause in clauses}

    # Convert query to uppercase for case-insensitive matching
    query_upper = query.upper()

    # Count the number of attributes in each clause
    for clause in clauses:
        if clause in query_upper:
            if clause == 'SELECT':
                select_parts = re.findall(r'(?i)(?<=SELECT)(.*?)(?=FROM|$)', query, re.DOTALL)
                for select_part in select_parts:
                    select_attributes = [i.strip().split(' AS ')[-1] for i in select_part.split(',') if i.strip()]
                    attributes['SELECT'].append(select_attributes)
                    counts['SELECT'] += len(select_attributes)
            elif clause == 'FROM':
                from_part = re.search(r'(?i)FROM\s+(.*?)(?=\bWHERE|\bGROUP BY|\bHAVING|\bORDER BY|\bUNION|\b$)', query, re.DOTALL).group(1).strip()
                from_attributes = from_part.split()[0]
                attributes['FROM'].append(from_attributes)
                counts['FROM'] += 1
            elif clause == 'WHERE':
                where_part = re.search(r'(?i)\bWHERE\b\s+(.*?)(?=\bGROUP BY\b|\bHAVING\b|\bORDER BY\b|\bUNION\b|$)', query, re.DOTALL)
                if where_part:
                    where_conditions = where_part.group(1).strip().split('AND')
                    where_conditions = [condition.strip() for condition in where_conditions]
                    attributes['WHERE'].extend(where_conditions)
                    counts['WHERE'] += len(where_conditions)
            elif clause == 'GROUP BY':
                group_by_part = re.search(r'(?i)\bGROUP BY\b\s+(.*?)(?=\bHAVING\b|$)', query, re.DOTALL)
                if group_by_part:
                    group_by_attributes = [attr.strip() for attr in group_by_part.group(1).split(',')]
                    attributes['GROUP BY'].extend(group_by_attributes)
                    counts['GROUP BY'] += len(group_by_attributes)
            elif clause == 'HAVING':
                having_part = re.search(r'(?i)\bHAVING\b\s+(.*?)(?=\bORDER BY\b|\bUNION\b|$)', query, re.DOTALL)
                if having_part:
                    having_conditions = having_part.group(1).strip().split('AND')
                    having_conditions = [condition.strip() for condition in having_conditions]
                    attributes['HAVING'].extend(having_conditions)
                    counts['HAVING'] += len(having_conditions)
            elif clause in ['JOIN', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']:
                join_parts = re.findall(r'(?i)\b' + clause + r'\b\s+(.*?)\bON\b', query, re.DOTALL)
                for part in join_parts:
                    tables_with_aliases = re.findall(r'(\w+\.\w+)', part)
                    tables = [table.strip() for table in tables_with_aliases]
                    attributes['JOIN'].extend(tables)
                    counts['JOIN'] += len(tables)

    # Convert the counts to a DataFrame
    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    df['Attributes'] = list(attributes.values())
    # Remove duplicates from the 'JOIN' attribute
    df.loc[df['Attribute'] == 'JOIN', 'Attributes'] = df.loc[df['Attribute'] == 'JOIN', 'Attributes'].apply(lambda x: list(set(x)))
    df.loc[df['Attribute'] == 'JOIN', 'Count'] = len(df.loc[df['Attribute'] == 'JOIN', 'Attributes'].values[0])
    return df


query_lc = """select d.name as departmentname, avg(e.salary) as averagesalary, count(e.id) as numberofemployees, l.location as location
from ascend.department d
join Ascend.employee e on d.id = e.department_id
outer join Ascend.location l on d.location_id = l.id
left join Ascend.route r on r.place= e.place
where e.hire_date > '2020-01-01' and r.route="houtrori"
group by d.name, l.location
having count(e.id) > 5 and avg(e.salary) > 50000;"""

df_lc = count_sql_attributes(query_lc)
print(df_lc)

print("--------------")

query_uc = """SELECT D.name AS DepartmentName, AVG(E.salary) AS AverageSalary, COUNT(E.id) AS NumberOfEmployees, L.location AS Location
FROM ascend.Department D
INNER JOIN Ascend.Employee E ON D.id = E.department_id
OUTER JOIN Ascend.Location L ON D.location_id = L.id
LEFT JOIN Ascend.ROUTE R ON R.Place= E.Place
WHERE E.hire_date > '2020-01-01' AND R.ROUTE="Houtrori"
GROUP BY D.name, L.location
HAVING COUNT(E.id) > 5 AND AVG(E.salary) > 50000;"""

df_uc = count_sql_attributes(query_uc)
print(df_uc)


#---
# 16/04/25 17:53
import re
import pandas as pd

def count_sql_attributes(query):
    # Define the SQL clauses and join types
    clauses = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING','JOIN', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']

    # Initialize a dictionary to store the counts and attributes
    counts = {clause: 0 for clause in clauses}
    attributes = {clause: [] for clause in clauses}

    # Convert query to uppercase for case-insensitive matching
    query_upper = query.upper()

    # Count the number of attributes in each clause
    for clause in clauses:
        if clause in query_upper:
            if clause == 'SELECT':
                select_parts = re.findall(r'(?i)(?<=SELECT)(.*?)(?=FROM|$)', query, re.DOTALL)
                for select_part in select_parts:
                    select_attributes = [i.strip().split(' AS ')[-1] for i in select_part.split(',') if i.strip()]
                    attributes['SELECT'].append(select_attributes)
                    counts['SELECT'] += len(select_attributes)
            elif clause == 'FROM':
                from_part = re.search(r'(?i)FROM\s+(.*?)(?=\bINNER JOIN|\bLEFT JOIN|\bRIGHT JOIN|\bOUTER JOIN|\bWHERE|\bGROUP BY|\bHAVING|$)', query, re.DOTALL).group(1).strip()
                from_subquery_match = re.search(r'(?i)\((.*?)\)', from_part)
                if from_subquery_match:
                    from_attributes = from_subquery_match.group(1).strip()
                else:
                    from_attributes = from_part.split('FROM')[-1].strip()

                # Extract table alias, if present
                from_alias_match = re.search(r'\b(\w+)\s+AS\b', from_attributes)
                if from_alias_match:
                    from_alias = from_alias_match.group(1)
                    attributes['FROM'].append(from_alias)
                else:
                    attributes['FROM'].append(from_attributes)
                counts['FROM'] += 1

            elif clause == 'WHERE':
                where_part = re.search(r'(?i)\bWHERE\b\s+(.*?)(?=\bGROUP BY\b|\bHAVING\b|\bORDER BY\b|\bUNION\b|$)', query, re.DOTALL)
                if where_part:
                    where_conditions = where_part.group(1).strip().split('AND')
                    where_conditions = [condition.strip() for condition in where_conditions]
                    attributes['WHERE'].extend(where_conditions)
                    counts['WHERE'] += len(where_conditions)
            elif clause == 'GROUP BY':
                group_by_part = re.search(r'(?i)\bGROUP BY\b\s+(.*?)(?=\bHAVING\b|$)', query, re.DOTALL)
                if group_by_part:
                    group_by_attributes = [attr.strip() for attr in group_by_part.group(1).split(',')]
                    attributes['GROUP BY'].extend(group_by_attributes)
                    counts['GROUP BY'] += len(group_by_attributes)
            elif clause == 'HAVING':
                having_part = re.search(r'(?i)\bHAVING\b\s+(.*?)(?=\bORDER BY\b|\bUNION\b|$)', query, re.DOTALL)
                if having_part:
                    having_conditions = having_part.group(1).strip().split('AND')
                    having_conditions = [condition.strip() for condition in having_conditions]
                    attributes['HAVING'].extend(having_conditions)
                    counts['HAVING'] += len(having_conditions)

    # Extract join clauses and their attributes
    join_types = ['JOIN', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']
    for join_type in join_types:
        join_parts = re.findall(r'(?i)\b' + join_type + r'\b\s*(.*?)\bON\b', query, re.DOTALL)
        for part in join_parts:
            tables_with_aliases = re.findall(r'\b[a-zA-Z]+\b', part)
            tables = [table.strip() for i, table in enumerate(tables_with_aliases) if i % 2 == 0 and table.strip()]
            attributes[join_type].extend(tables)
            counts[join_type] += len(tables)

    # Convert the counts to a DataFrame
    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    df['Attributes'] = list(attributes.values())
    return df




query_lc = """select d.name as departmentname, avg(e.salary) as averagesalary, count(e.id) as numberofemployees, l.location as location
from department d
join employee e on d.id = e.department_id
outer join location l on d.location_id = l.id
left join route r on r.place= e.place
where e.hire_date > '2020-01-01' and r.route="houtrori"
group by d.name, l.location
having count(e.id) > 5 and avg(e.salary) > 50000;"""

df_lc = count_sql_attributes(query_lc)
print(df_lc)

print("--------------")

query_uc = """SELECT D.name AS DepartmentName, AVG(E.salary) AS AverageSalary, COUNT(E.id) AS NumberOfEmployees, L.location AS Location
FROM Department D
INNER JOIN Employee E ON D.id = E.department_id
OUTER JOIN Location L ON D.location_id = L.id
LEFT JOIN ROUTE R ON R.Place= E.Place
WHERE E.hire_date > '2020-01-01' AND R.ROUTE="Houtrori"
GROUP BY D.name, L.location
HAVING COUNT(E.id) > 5 AND AVG(E.salary) > 50000;"""

df_uc = count_sql_attributes(query_uc)
print(df_uc)

#---
#16/04/24
import re
import pandas as pd

def count_sql_attributes(query):
    # Define the SQL clauses and join types
    clauses = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']

    # Initialize a dictionary to store the counts and attributes
    counts = {clause: 0 for clause in clauses}
    attributes = {clause: [] for clause in clauses}

    # Convert query to uppercase for case-insensitive matching
    query_upper = query.upper()

    # Count the number of attributes in each clause
    for clause in clauses:
        if clause in query_upper:
            if clause == 'SELECT':
                select_parts = re.findall(r'(?i)(?<=SELECT)(.*?)(?=FROM|$)', query, re.DOTALL)
                for select_part in select_parts:
                    select_attributes = [i.strip().split(' AS ')[-1] for i in select_part.split(',') if i.strip()]
                    attributes['SELECT'].append(select_attributes)
                    counts['SELECT'] += len(select_attributes)
            elif clause == 'FROM':
                from_part = re.search(r'(?i)FROM\s+(.*?)(?=\bINNER JOIN|\bLEFT JOIN|\bRIGHT JOIN|\bOUTER JOIN|\bWHERE|\bGROUP BY|\bHAVING|$)', query, re.DOTALL).group(1).strip()
                from_subquery_match = re.search(r'(?i)\((.*?)\)', from_part)
                if from_subquery_match:
                    from_attributes = from_subquery_match.group(1).strip()
                else:
                    from_attributes = from_part.split('FROM')[-1].strip()

                # Extract table alias, if present
                from_alias_match = re.search(r'\b(\w+)\s+AS\b', from_attributes)
                if from_alias_match:
                    from_alias = from_alias_match.group(1)
                    attributes['FROM'].append(from_alias)
                else:
                    attributes['FROM'].append(from_attributes)
                counts['FROM'] += 1

            elif clause == 'WHERE':
                where_part = re.search(r'(?i)\bWHERE\b\s+(.*?)(?=\bGROUP BY\b|\bHAVING\b|\bORDER BY\b|\bUNION\b|$)', query, re.DOTALL)
                if where_part:
                    where_conditions = where_part.group(1).strip().split('AND')
                    where_conditions = [condition.strip() for condition in where_conditions]
                    attributes['WHERE'].extend(where_conditions)
                    counts['WHERE'] += len(where_conditions)
            elif clause == 'GROUP BY':
                group_by_part = re.search(r'(?i)\bGROUP BY\b\s+(.*?)(?=\bHAVING\b|$)', query, re.DOTALL)
                if group_by_part:
                    group_by_attributes = [attr.strip() for attr in group_by_part.group(1).split(',')]
                    attributes['GROUP BY'].extend(group_by_attributes)
                    counts['GROUP BY'] += len(group_by_attributes)
            elif clause == 'HAVING':
                having_part = re.search(r'(?i)\bHAVING\b\s+(.*?)(?=\bORDER BY\b|\bUNION\b|$)', query, re.DOTALL)
                if having_part:
                    having_conditions = having_part.group(1).strip().split('AND')
                    having_conditions = [condition.strip() for condition in having_conditions]
                    attributes['HAVING'].extend(having_conditions)
                    counts['HAVING'] += len(having_conditions)

    # Extract join clauses and their attributes
    join_types = ['INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']
    for join_type in join_types:
        join_parts = re.findall(r'(?i)\b' + join_type + r'\b\s*(.*?)\bON\b', query, re.DOTALL)
        for part in join_parts:
            tables_with_aliases = re.findall(r'\b[a-zA-Z]+\b', part)
            tables = [table.strip() for i, table in enumerate(tables_with_aliases) if i % 2 == 0 and table.strip()]
            attributes[join_type].extend(tables)
            counts[join_type] += len(tables)

    # Convert the counts to a DataFrame
    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    df['Attributes'] = list(attributes.values())
    return df

#----

import re
import pandas as pd

def count_sql_attributes(query):
    # Define the SQL clauses and join types
    clauses = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']

    # Initialize a dictionary to store the counts and attributes
    counts = {clause: 0 for clause in clauses}
    attributes = {clause: [] for clause in clauses}

    # Count the number of attributes in each clause
    for clause in clauses:
        if clause in query.upper():
            if clause == 'SELECT':
                select_parts = re.findall(r'(?i)(?<=SELECT)(.*?)(?=FROM|$)', query, re.DOTALL)
                for select_part in select_parts:
                    select_attributes = [i.strip().split(' AS ')[-1] for i in select_part.split(',') if i.strip()]
                    attributes['SELECT'].append(select_attributes)
                    counts['SELECT'] += len(select_attributes)
            elif clause == 'FROM':
                from_part = re.search(r'(?i)FROM\s+(.*?)(?=\bINNER JOIN|\bLEFT JOIN|\bRIGHT JOIN|\bOUTER JOIN|\bWHERE|\bGROUP BY|\bHAVING|$)', query, re.DOTALL).group(1).strip()
                from_subquery_match = re.search(r'(?i)\((.*?)\)', from_part)
                if from_subquery_match:
                    from_attributes = from_subquery_match.group(1).strip()
                else:
                    from_attributes = from_part.split('FROM')[-1].strip()

                # Extract table alias, if present
                from_alias_match = re.search(r'\b(\w+)\s+AS\b', from_attributes)
                if from_alias_match:
                    from_alias = from_alias_match.group(1)
                    attributes['FROM'].append(from_alias)
                else:
                    attributes['FROM'].append(from_attributes)
                counts['FROM'] += 1

            elif clause == 'WHERE':
                where_part = query.split('WHERE')[1].split('GROUP BY')[0].strip()
                attributes['WHERE'].append(where_part)
                counts['WHERE'] += 1
            elif clause == 'GROUP BY':
                group_by_part = query.split('GROUP BY')[1].split('HAVING')[0].strip()
                group_by_attributes = [attr.strip() for attr in group_by_part.split(',')]
                attributes['GROUP BY'].extend(group_by_attributes)
                counts['GROUP BY'] += len(group_by_attributes)
            elif clause == 'HAVING':
                condition = re.search(r'(?i)\b' + clause + r'\b\s*(.+?)(?=\bGROUP BY\b|$)', query)
                if condition:
                    condition_text = condition.group(1).strip()
                    attributes[clause].append(condition_text)
                    counts[clause] += 1

    # Extract join clauses and their attributes
    join_types = ['INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']
    for join_type in join_types:
        join_parts = re.findall(r'(?i)\b' + join_type + r'\b\s*(.*?)\bON\b', query)
        for part in join_parts:
            tables_with_aliases = re.findall(r'\b[a-zA-Z]+\b', part)
            tables = [table.strip() for i, table in enumerate(tables_with_aliases) if i % 2 == 0 and table.strip()]
            attributes[join_type].extend(tables)
            counts[join_type] += len(tables)

    # Convert the counts to a DataFrame
    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    df['Attributes'] = list(attributes.values())
    return df

query = """SELECT D.name AS DepartmentName, AVG(E.salary) AS AverageSalary, COUNT(E.id) AS NumberOfEmployees, L.location AS Location
FROM (SELECT * FROM Department WHERE dept_id=12) D
INNER JOIN Employee E ON D.id = E.department_id
OUTER JOIN Location L ON D.location_id = L.id
LEFT JOIN ROUTE R ON R.Place= E.Place
WHERE E.hire_date > '2020-01-01' AND R.ROUTE="Houtrori"
GROUP BY D.name, L.location
HAVING COUNT(E.id) > 5 AND AVG(E.salary) > 50000;"""

df = count_sql_attributes(query)
print(df)

#--
import re
import pandas as pd

def count_sql_attributes(query):
    # Define the SQL clauses and join types
    clauses = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']

    # Initialize a dictionary to store the counts and attributes
    counts = {clause: 0 for clause in clauses}
    attributes = {clause: [] for clause in clauses}

    # Count the number of attributes in each clause
    for clause in clauses:
        if clause in query.upper():
            if clause == 'SELECT':
                select_parts = re.findall(r'(?i)(?<=SELECT)(.*?)(?=FROM|$)', query, re.DOTALL)
                for select_part in select_parts:
                    select_attributes = [i.strip().split(' AS ')[-1] for i in select_part.split(',') if i.strip()]
                    attributes['SELECT'].append(select_attributes)
                    counts['SELECT'] += len(select_attributes)
            elif clause == 'FROM':
                from_part = re.search(r'(?i)FROM\s+(.*?)(?=\bINNER JOIN|\bLEFT JOIN|\bRIGHT JOIN|\bOUTER JOIN|\bWHERE|\bGROUP BY|\bHAVING|$)', query, re.DOTALL).group(1).strip()
                from_subquery_match = re.search(r'(?i)\((.*?)\)', from_part)
                if from_subquery_match:
                    from_attributes = from_subquery_match.group(1).strip()
                else:
                    from_attributes = from_part.split('FROM')[-1].strip()

                # Extract table alias, if present
                from_alias_match = re.search(r'\b(\w+)\s+AS\b', from_attributes)
                if from_alias_match:
                    from_alias = from_alias_match.group(1)
                    attributes['FROM'].append(from_alias)
                else:
                    attributes['FROM'].append(from_attributes)
                counts['FROM'] += 1

            elif clause == 'WHERE':
                where_part = re.search(r'(?i)\bWHERE\b\s+(.*?)(?=\bGROUP BY\b|\bHAVING\b|\bORDER BY\b|\bUNION\b|$)', query, re.DOTALL).group(1).strip()
                where_conditions = re.findall(r'\b\w+\b\s*[!=><]+\s*[\'"]?[\w\s]*[\'"]?', where_part)
                attributes['WHERE'].extend([condition.strip() for condition in where_conditions])
                counts['WHERE'] += len(where_conditions)
            elif clause == 'GROUP BY':
                group_by_part = query.split('GROUP BY')[1].split('HAVING')[0].strip()
                group_by_attributes = [attr.strip() for attr in group_by_part.split(',')]
                attributes['GROUP BY'].extend(group_by_attributes)
                counts['GROUP BY'] += len(group_by_attributes)
            elif clause == 'HAVING':
                condition = re.search(r'(?i)\b' + clause + r'\b\s*(.+?)(?=\bGROUP BY\b|$)', query)
                if condition:
                    condition_text = condition.group(1).strip()
                    attributes[clause].append(condition_text)
                    counts[clause] += 1

    # Extract join clauses and their attributes
    join_types = ['INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']
    for join_type in join_types:
        join_parts = re.findall(r'(?i)\b' + join_type + r'\b\s*(.*?)\bON\b', query)
        for part in join_parts:
            tables_with_aliases = re.findall(r'\b[a-zA-Z]+\b', part)
            tables = [table.strip() for i, table in enumerate(tables_with_aliases) if i % 2 == 0 and table.strip()]
            attributes[join_type].extend(tables)
            counts[join_type] += len(tables)

    # Convert the counts to a DataFrame
    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    df['Attributes'] = list(attributes.values())
    return df
query = """SELECT D.name AS DepartmentName, AVG(E.salary) AS AverageSalary, COUNT(E.id) AS NumberOfEmployees, L.location AS Location
FROM (SELECT * FROM Department WHERE dept_id=32) D
INNER JOIN Employee E ON D.id = E.department_id
OUTER JOIN Location L ON D.location_id = L.id
LEFT JOIN ROUTE R ON R.Place= E.Place
WHERE E.hire_date > '2020-01-01' AND R.ROUTE="Houtrori"
GROUP BY D.name, L.location
HAVING COUNT(E.id) > 5 AND AVG(E.salary) > 50000;"""

df = count_sql_attributes(query)
print(df)

#---
import re
import pandas as pd

def count_sql_attributes(query):
    # Define the SQL clauses and join types
    clauses = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'HAVING', 'INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN', 'WITH']

    # Initialize a dictionary to store the counts and attributes
    counts = {clause: 0 for clause in clauses}
    attributes = {clause: [] for clause in clauses}

    # Count the number of attributes in each clause
    for clause in clauses:
        if clause in query.upper():
            if clause == 'SELECT':
                select_parts = re.findall(r'(?i)(?<=SELECT)(.*?)(?=FROM|$)', query, re.DOTALL)
                for select_part in select_parts:
                    select_attributes = [i.strip().split(' AS ')[-1] for i in select_part.split(',') if i.strip()]
                    attributes['SELECT'].append(select_attributes)
                    counts['SELECT'] += len(select_attributes)
            elif clause == 'FROM':
                from_part = query.split('WHERE')[0].split('FROM')[1].strip()
                from_attributes = [i.strip() for i in from_part.split(',') if i.strip()]
                attributes['FROM'].extend(from_attributes)
                counts['FROM'] += len(from_attributes)
            elif clause == 'WHERE':
                where_part = query.split('WHERE')[1].split('GROUP BY')[0].strip()
                attributes['WHERE'].append(where_part)
                counts['WHERE'] += 1
            elif clause == 'GROUP BY':
                group_by_part = query.split('GROUP BY')[1].split('HAVING')[0].strip()
                group_by_attributes = [attr.strip() for attr in group_by_part.split(',')]
                attributes['GROUP BY'].extend(group_by_attributes)
                counts['GROUP BY'] += len(group_by_attributes)
            elif clause == 'HAVING':
                condition = re.search(r'(?i)\b' + clause + r'\b\s*(.+?)(?=\bGROUP BY\b|$)', query)
                if condition:
                    condition_text = condition.group(1).strip()
                    attributes[clause].append(condition_text)
                    counts[clause] += 1
            elif clause == 'WITH':
                cte_part = query.split('SELECT')[0].strip()
                cte_name = re.search(r'(?i)\bAS\b\s*([^\s]+)', cte_part).group(1)
                cte_select_parts = re.findall(r'(?i)(?<=SELECT)(.*?)(?=FROM|$)', cte_part, re.DOTALL)
                cte_attributes = []
                for cte_select_part in cte_select_parts:
                    cte_select_attributes = [i.strip().split(' AS ')[-1] for i in cte_select_part.split(',') if i.strip()]
                    cte_attributes.append(cte_select_attributes)
                    counts['SELECT'] += len(cte_select_attributes)
                attributes['WITH'].append({cte_name: cte_attributes})
                counts['WITH'] += 1

    # Extract join clauses and their attributes
    join_types = ['INNER JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'OUTER JOIN']
    for join_type in join_types:
        join_parts = re.findall(r'(?i)\b' + join_type + r'\b\s*(.*?)\bON\b', query)
        for part in join_parts:
            tables_with_aliases = re.findall(r'\b[a-zA-Z]+\b', part)
            tables = [table.strip() for i, table in enumerate(tables_with_aliases) if i % 2 == 0 and table.strip()]
            attributes[join_type].extend(tables)
            counts[join_type] += len(tables)

    # Convert the counts to a DataFrame
    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    df['Attributes'] = list(attributes.values())
    return df

query = """WITH avg_per_store AS
  (SELECT store, AVG(amount) AS average_order
   FROM orders
   GROUP BY store)
SELECT o.id, o.store, o.amount, avg.average_order AS avg_for_store
FROM orders o
JOIN avg_per_store avg
ON o.store = avg.store;"""

query1 = """SELECT D.name AS DepartmentName, AVG(E.salary) AS AverageSalary, COUNT(E.id) AS NumberOfEmployees, L.location AS Location
    ...: FROM (SELECT * FROM Department WHERE dept_id=32) D
    ...: INNER JOIN Employee E ON D.id = E.department_id
    ...: OUTER JOIN Location L ON D.location_id = L.id
         LEFT JOIN ROUTE R ON R.Place= E.Place
    ...: WHERE E.hire_date > '2020-01-01' AND R.ROUTE="Houtrori"
    ...: GROUP BY D.name, L.location
    ...: HAVING COUNT(E.id) > 5 AND AVG(E.salary) > 50000;"""

df = count_sql_attributes(query1)
print(df)

#---
import re
import pandas as pd

def count_sql_attributes(query):
    # Define the SQL clauses
    clauses = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'JOIN', 'INNER JOIN', 'OUTER JOIN', 'HAVING']

    # Initialize a dictionary to store the counts
    counts = {clause: 0 for clause in clauses}
    attributes = {clause: [] for clause in clauses}

    # Count the number of attributes in each clause
    for clause in clauses:
        if clause in query:
            if clause == 'SELECT':
                select_part = query.split('FROM')[0].split('SELECT')[1]
                attributes['SELECT'] = [i.strip() for i in select_part.split(',') if i.strip()]
                counts['SELECT'] = len(attributes['SELECT'])
            elif clause in ['JOIN', 'INNER JOIN', 'OUTER JOIN']:
                join_part = query.split('ON')[0].split(clause)[1]
                attributes[clause] = [i.strip() for i in join_part.split(',') if i.strip()]
                counts[clause] = len(attributes[clause])
            else:
                counts[clause] = 1

    # Convert the counts to a DataFrame
    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    df['Attributes'] = list(attributes.values())
    return df

query = "SELECT ty.yui, ty.iuyt, ty.oiu,ru.kj FROM trise tr INNER JOIN ruise ru ON ru.id=tr.id"
df = count_sql_attributes(query)
print(df)





import sqlparse
import pandas as pd

def count_sql_attributes(query):
    parsed = sqlparse.parse(query)[0]
    tokens = parsed.tokens
    attributes = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'JOIN']
    counts = {attr: 0 for attr in attributes}

    for token in tokens:
        if token.ttype is None and str(token) in attributes:
            if str(token) == 'SELECT':
                select_list = str(token.get_parent()).split('SELECT')[1].split('FROM')[0]
                counts['SELECT'] = len([i.strip() for i in select_list.split(',') if i.strip()])
            else:
                counts[str(token)] += 1

    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    return df

query = "SELECT ty.yui, ty.iuyt, ty.oiu,ru.kj FROM trise tr JOIN ruise ru ON ru.id=tr.id"
df = count_sql_attributes(query)
print(df)







import re
import pandas as pd

def count_sql_attributes(query):
    # Define the SQL clauses
    clauses = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'JOIN', 'INNER JOIN', 'OUTER JOIN', 'HAVING']

    # Initialize a dictionary to store the counts
    counts = {clause: 0 for clause in clauses}

    # Count the number of attributes in each clause
    for clause in clauses:
        if clause in query:
            if clause == 'SELECT':
                select_part = query.split('FROM')[0].split('SELECT')[1]
                counts['SELECT'] = len([i.strip() for i in select_part.split(',') if i.strip()])
            elif clause in ['JOIN', 'INNER JOIN', 'OUTER JOIN']:
                join_part = query.split('ON')[0].split(clause)[1]
                counts[clause] = len([i.strip() for i in join_part.split(',') if i.strip()])
            else:
                counts[clause] = 1

    # Convert the counts to a DataFrame
    df = pd.DataFrame(list(counts.items()), columns=['Attribute', 'Count'])
    return df

query = "SELECT ty.yui, ty.iuyt, ty.oiu,ru.kj FROM trise tr INNER JOIN ruise ru ON ru.id=tr.id"
df = count_sql_attributes(query)
print(df)



import re

def extract_sql(text):
    pattern = r'```(.*?)```'
    matches = re.findall(pattern, text, re.DOTALL)
    return matches

text = """This is the final extracted data for the query asked by the user uer. This is the hive query ```SELECT * FROM Br_Premium_data``` This query may not the be most suitable one please check your attributes correctly"""

print(extract_sql(text))


import pandas as pd

def add_column_using_function(df, func, new_col_name):
    """
    Add a new column to the DataFrame using a provided function.

    Parameters:
    df (DataFrame): The DataFrame to add a new column to.
    func (function): The function to apply to each row of the DataFrame.
    new_col_name (str): The name of the new column.

    Returns:
    DataFrame: The DataFrame with the new column added.
    """
    df[new_col_name] = df.apply(func, axis=1)
    return df


from nltk.util import ngrams

def rouge_n(reference, hypothesis, n):
    # Convert the generator to a set
    ref_ngrams = set(ngrams(reference, n))
    hyp_ngrams = set(ngrams(hypothesis, n))

    # Calculate the intersection of the two sets
    common = ref_ngrams.intersection(hyp_ngrams)

    # Return the ratio of common ngrams to reference ngrams
    return len(common) / len(ref_ngrams)

from nltk.util import ngrams

def rouge_n_fmeasure(reference, hypothesis, n):
    # Convert the generator to a set
    ref_ngrams = set(ngrams(reference, n))
    hyp_ngrams = set(ngrams(hypothesis, n))

    # Calculate the intersection of the two sets
    common = ref_ngrams.intersection(hyp_ngrams)

    # Calculate precision, recall, and F-measure
    precision = len(common) / len(hyp_ngrams) if hyp_ngrams else 0
    recall = len(common) / len(ref_ngrams) if ref_ngrams else 0
    f_measure = 2 * precision * recall / (precision + recall) if precision + recall else 0

    # Return the F-measure
    return f_measure


def count_words_and_chars(sentence):
    # Count the number of words in the sentence
    word_count = len(sentence.split())

    # Count the number of characters in the sentence
    char_count = len(sentence)

    return word_count, char_count




from nltk.translate.bleu_score import sentence_bleu
def bleu_score(reference, hypothesis):
    return sentence_bleu([reference], hypothesis)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
 
def cos_sim(text1, text2):
    vectorizer = TfidfVectorizer()
    tfidf = vectorizer.fit_transform([text1, text2])
    return cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]
